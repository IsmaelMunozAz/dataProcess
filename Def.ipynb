{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings # supress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-0468adb4c0c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcorrMatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiverging_palette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m220\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0msquare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/seaborn/palettes.py\u001b[0m in \u001b[0;36mdiverging_palette\u001b[0;34m(h_neg, h_pos, s, l, sep, n, center, as_cmap)\u001b[0m\n\u001b[1;32m    742\u001b[0m     \"\"\"\n\u001b[1;32m    743\u001b[0m     \u001b[0mpalfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdark_palette\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcenter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"dark\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlight_palette\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m     \u001b[0mneg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpalfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"husl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m     \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpalfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"husl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     midpoint = dict(light=[(.95, .95, .95, 1.)],\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/seaborn/palettes.py\u001b[0m in \u001b[0;36mlight_palette\u001b[0;34m(color, n_colors, reverse, as_cmap, input)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mlight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_hls_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.95\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlight\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mblend_palette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_colors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_cmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/seaborn/palettes.py\u001b[0m in \u001b[0;36mblend_palette\u001b[0;34m(colors, n_colors, as_cmap, input)\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0mpal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearSegmentedColormap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mas_cmap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0mpal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ColorPalette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_colors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mlinspace\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/numpy/core/function_base.py\u001b[0m in \u001b[0;36mlinspace\u001b[0;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \"\"\"\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of samples, %s, must be non-negative.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "#Firstly, we read the dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "np.random.seed(8)\n",
    "\n",
    "#Then, we plot a correlation matrix to find the correlation between the class and the rest of our variables. As we can see, all values are pretty low (none of them go past ~0.25).\n",
    "#The ideal would be >0.5.\n",
    "corrMatrix = df.corr()\n",
    "\n",
    "#We can plot it into a heatmap, for a more visual take on it.\n",
    "ax = sns.heatmap(\n",
    "    corrMatrix, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "\n",
    "corrMatrix.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    13156\n",
      "0.0     2842\n",
      "Name: relevant, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Printing the values our class takes allows us to realize that it's incredibly imbalanced. We will correct this later.\n",
    "print(df['relevant'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality              0.250797\n",
      "bits                 0.252393\n",
      "skip_parts           0.241371\n",
      "inter_other_parts    0.195646\n",
      "non_zero_pixels      0.236884\n",
      "frame_width          0.148213\n",
      "frame_height         0.137324\n",
      "sub_mean_1           0.141184\n",
      "sub_mean_2           0.138525\n",
      "sub_mean_3           0.151905\n",
      "sub_mean_4           0.179225\n",
      "sobel_h              0.194505\n",
      "sobel_v              0.197248\n",
      "relevant             1.000000\n",
      "Name: relevant, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#In order to do some feature selection, we use our previously plotted correlation matrix.\n",
    "cor_target = abs(corrMatrix[\"relevant\"])\n",
    "#Then we select our \"highly correlated\" features. Given how low all the values are, our standards have to be just as low in order to pick any variables at all.\n",
    "relevant_features = cor_target[cor_target>0.12]\n",
    "print(relevant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality              False\n",
      "bits                 False\n",
      "skip_parts           False\n",
      "inter_other_parts    False\n",
      "non_zero_pixels      False\n",
      "frame_width          False\n",
      "frame_height         False\n",
      "sub_mean_1           False\n",
      "sub_mean_2           False\n",
      "sub_mean_3            True\n",
      "sub_mean_4           False\n",
      "sobel_h              False\n",
      "sobel_v              False\n",
      "relevant              True\n",
      "dtype: bool\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#We get rid of the variables we deem not important enough for our model.\n",
    "df.pop('block_movement_h')\n",
    "df.pop('block_movement_v')\n",
    "df.pop('var_movement_h')\n",
    "df.pop('var_movement_v')\n",
    "df.pop('cost_1')\n",
    "df.pop('cost_2')\n",
    "df.pop('inter_16x16_parts')\n",
    "df.pop('movement_level')\n",
    "df.pop('mean')\n",
    "df.pop('var_sub_blocks')\n",
    "df.pop('intra_parts')\n",
    "df.pop('inter_4x4_parts')\n",
    "df.pop('variance')\n",
    "\n",
    "#The following are just comprobations to figure out if we have any null (missing) or non-finite values. \n",
    "print(df.isnull().any())\n",
    "print(np.any(np.isnan(df))) \n",
    "print(np.all(np.isfinite(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_mask = (df.dtypes==object)\n",
    "cat_cols = df.columns[cat_mask].tolist()\n",
    "df_cat = df[cat_cols]\n",
    "df_num = df.drop(cat_cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#To take care of our missing values, we will use SingleImputer, replacing those null values with our mean for that variable.\n",
    "imp_num = SimpleImputer(strategy='mean')\n",
    "columns = df_num.columns\n",
    "index = df_num.index\n",
    "df_num = pd.DataFrame(imp_num.fit_transform(df_num),columns=columns,index=index)\n",
    "df_preprocessed=df_num\n",
    "df_preprocessed=df_preprocessed.astype(int)\n",
    "\n",
    "#We check whether our missing values are gone (they are).\n",
    "print(np.any(np.isnan(df_preprocessed))) \n",
    "print(np.all(np.isfinite(df_preprocessed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some of our values have a very high variance, so we normalize our data to reduce their impact on our conclusions.\n",
    "df_columns=df_preprocessed.columns\n",
    "mms = MinMaxScaler()\n",
    "df_preprocessed = mms.fit_transform(df_preprocessed)\n",
    "df_preprocessed=pd.DataFrame(df_preprocessed)\n",
    "df.columns=df_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       quality      bits  skip_parts  inter_other_parts  non_zero_pixels  \\\n",
      "0          0.0  0.449172        0.00           0.777778         0.487923   \n",
      "1          0.0  0.363655        0.50           0.296296         0.460145   \n",
      "2          0.0  0.413121        0.00           0.296296         0.555556   \n",
      "3          0.0  0.518340        0.00           0.740741         0.508454   \n",
      "4          0.0  0.229092        0.00           0.296296         0.201691   \n",
      "5          0.0  0.213372        0.00           0.296296         0.241546   \n",
      "6          0.0  0.105429        0.00           0.222222         0.100242   \n",
      "7          0.0  0.325299        0.00           0.370370         0.371981   \n",
      "8          0.0  0.170824        0.25           0.370370         0.194444   \n",
      "9          0.0  0.077342        0.25           0.148148         0.092995   \n",
      "10         0.0  0.005450        0.50           0.000000         0.000000   \n",
      "11         0.0  0.065395        0.00           0.296296         0.065217   \n",
      "12         0.0  0.185496        0.25           0.074074         0.230676   \n",
      "13         0.0  0.197862        0.00           0.333333         0.217391   \n",
      "14         0.0  0.211486        0.00           0.444444         0.205314   \n",
      "15         0.0  0.250262        0.25           0.333333         0.328502   \n",
      "16         0.0  0.148397        0.00           0.592593         0.154589   \n",
      "17         0.0  0.163907        0.25           0.370370         0.198068   \n",
      "18         0.0  0.375603        0.00           0.296296         0.512077   \n",
      "19         0.0  0.127227        0.25           0.296296         0.121981   \n",
      "20         0.0  0.073569        0.25           0.185185         0.067633   \n",
      "21         0.0  0.035842        0.25           0.000000         0.027778   \n",
      "22         0.0  0.012995        0.50           0.296296         0.000000   \n",
      "23         0.0  0.346259        0.00           0.703704         0.324879   \n",
      "24         0.0  0.049466        0.50           0.074074         0.048309   \n",
      "25         0.0  0.124293        0.25           0.333333         0.146135   \n",
      "26         0.0  0.123245        0.25           0.111111         0.159420   \n",
      "27         0.0  0.300566        0.00           0.481481         0.363527   \n",
      "28         0.0  0.410187        0.00           0.407407         0.438406   \n",
      "29         0.0  0.345001        0.25           0.333333         0.419082   \n",
      "...        ...       ...         ...                ...              ...   \n",
      "15970      1.0  0.046322        0.25           0.148148         0.024155   \n",
      "15971      1.0  0.028506        0.00           0.000000         0.015700   \n",
      "15972      1.0  0.041501        0.00           0.000000         0.032609   \n",
      "15973      1.0  0.033536        0.00           0.074074         0.021739   \n",
      "15974      1.0  0.031021        0.00           0.148148         0.008454   \n",
      "15975      1.0  0.044854        0.00           0.074074         0.025362   \n",
      "15976      1.0  0.035632        0.00           0.148148         0.031401   \n",
      "15977      1.0  0.029763        0.00           0.185185         0.015700   \n",
      "15978      1.0  0.051352        0.00           0.185185         0.027778   \n",
      "15979      1.0  0.028715        0.00           0.148148         0.036232   \n",
      "15980      1.0  0.003144        0.75           0.000000         0.000000   \n",
      "15981      1.0  0.046950        0.00           0.222222         0.016908   \n",
      "15982      1.0  0.020960        0.00           0.000000         0.008454   \n",
      "15983      1.0  0.003354        0.75           0.000000         0.000000   \n",
      "15984      1.0  0.003563        0.75           0.000000         0.000000   \n",
      "15985      1.0  0.005869        0.50           0.000000         0.000000   \n",
      "15986      1.0  0.004821        1.00           0.000000         0.002415   \n",
      "15987      1.0  0.006917        0.25           0.000000         0.019324   \n",
      "15988      1.0  0.002306        0.75           0.000000         0.000000   \n",
      "15989      1.0  0.007126        0.25           0.000000         0.000000   \n",
      "15990      1.0  0.004821        0.50           0.000000         0.000000   \n",
      "15991      1.0  0.006288        0.50           0.000000         0.000000   \n",
      "15992      1.0  0.015301        0.50           0.000000         0.009662   \n",
      "15993      1.0  0.026619        0.00           0.074074         0.030193   \n",
      "15994      1.0  0.025571        0.00           0.222222         0.004831   \n",
      "15995      1.0  0.013834        0.25           0.037037         0.003623   \n",
      "15996      1.0  0.020960        0.00           0.074074         0.009662   \n",
      "15997      1.0  0.029554        0.25           0.148148         0.018116   \n",
      "15998      1.0  0.070216        0.00           0.074074         0.045894   \n",
      "15999      1.0  0.047370        0.00           0.148148         0.028986   \n",
      "\n",
      "       frame_width  frame_height  sub_mean_1  sub_mean_2  sub_mean_3  \\\n",
      "0              0.0           0.0      0.1250    0.052632    0.102041   \n",
      "1              0.0           0.0      0.0375    0.052632    0.122449   \n",
      "2              0.0           0.0      0.0500    0.052632    0.183673   \n",
      "3              0.0           0.0      0.0750    0.065789    0.285714   \n",
      "4              0.0           0.0      0.0875    0.052632    0.000000   \n",
      "5              0.0           0.0      0.0125    0.039474    0.020408   \n",
      "6              0.0           0.0      0.0000    0.026316    0.000000   \n",
      "7              0.0           0.0      0.0625    0.065789    0.020408   \n",
      "8              0.0           0.0      0.0000    0.026316    0.000000   \n",
      "9              0.0           0.0      0.0000    0.026316    0.000000   \n",
      "10             0.0           0.0      0.0000    0.000000    0.000000   \n",
      "11             0.0           0.0      0.0125    0.000000    0.061224   \n",
      "12             0.0           0.0      0.0375    0.026316    0.061224   \n",
      "13             0.0           0.0      0.0250    0.065789    0.061224   \n",
      "14             0.0           0.0      0.0750    0.013158    0.081633   \n",
      "15             0.0           0.0      0.0250    0.013158    0.061224   \n",
      "16             0.0           0.0      0.0125    0.000000    0.000000   \n",
      "17             0.0           0.0      0.0000    0.000000    0.061224   \n",
      "18             0.0           0.0      0.0625    0.078947    0.122449   \n",
      "19             0.0           0.0      0.0125    0.013158    0.061224   \n",
      "20             0.0           0.0      0.0125    0.000000    0.020408   \n",
      "21             0.0           0.0      0.0000    0.013158    0.000000   \n",
      "22             0.0           0.0      0.0000    0.000000    0.000000   \n",
      "23             0.0           0.0      0.0000    0.026316    0.142857   \n",
      "24             0.0           0.0      0.0000    0.013158    0.000000   \n",
      "25             0.0           0.0      0.0000    0.052632    0.020408   \n",
      "26             0.0           0.0      0.0000    0.000000    0.020408   \n",
      "27             0.0           0.0      0.0125    0.013158    0.142857   \n",
      "28             0.0           0.0      0.0750    0.039474    0.081633   \n",
      "29             0.0           0.0      0.0375    0.039474    0.122449   \n",
      "...            ...           ...         ...         ...         ...   \n",
      "15970          1.0           1.0      0.0375    0.078947    0.081633   \n",
      "15971          1.0           1.0      0.0000    0.026316    0.020408   \n",
      "15972          1.0           1.0      0.0500    0.157895    0.020408   \n",
      "15973          1.0           1.0      0.0750    0.000000    0.040816   \n",
      "15974          1.0           1.0      0.0375    0.000000    0.020408   \n",
      "15975          1.0           1.0      0.0500    0.039474    0.122449   \n",
      "15976          1.0           1.0      0.0375    0.000000    0.000000   \n",
      "15977          1.0           1.0      0.0125    0.000000    0.061224   \n",
      "15978          1.0           1.0      0.0875    0.052632    0.102041   \n",
      "15979          1.0           1.0      0.0125    0.026316    0.244898   \n",
      "15980          1.0           1.0      0.0000    0.000000    0.000000   \n",
      "15981          1.0           1.0      0.1500    0.013158    0.000000   \n",
      "15982          1.0           1.0      0.0125    0.000000    0.000000   \n",
      "15983          1.0           1.0      0.0000    0.000000    0.000000   \n",
      "15984          1.0           1.0      0.0000    0.000000    0.000000   \n",
      "15985          1.0           1.0      0.0000    0.000000    0.000000   \n",
      "15986          1.0           1.0      0.0000    0.000000    0.000000   \n",
      "15987          1.0           1.0      0.0375    0.000000    0.000000   \n",
      "15988          1.0           1.0      0.0000    0.000000    0.000000   \n",
      "15989          1.0           1.0      0.0000    0.000000    0.000000   \n",
      "15990          1.0           1.0      0.0000    0.000000    0.000000   \n",
      "15991          1.0           1.0      0.0000    0.000000    0.000000   \n",
      "15992          1.0           1.0      0.0000    0.000000    0.122449   \n",
      "15993          1.0           1.0      0.0000    0.039474    0.142857   \n",
      "15994          1.0           1.0      0.0000    0.000000    0.020408   \n",
      "15995          1.0           1.0      0.0000    0.000000    0.061224   \n",
      "15996          1.0           1.0      0.0625    0.013158    0.020408   \n",
      "15997          1.0           1.0      0.1000    0.052632    0.000000   \n",
      "15998          1.0           1.0      0.0875    0.078947    0.061224   \n",
      "15999          1.0           1.0      0.0625    0.026316    0.122449   \n",
      "\n",
      "       sub_mean_4   sobel_h   sobel_v  relevant  \n",
      "0        0.157895  0.246377  0.257576       1.0  \n",
      "1        0.131579  0.202899  0.212121       1.0  \n",
      "2        0.184211  0.217391  0.196970       1.0  \n",
      "3        0.157895  0.304348  0.439394       1.0  \n",
      "4        0.026316  0.159420  0.212121       1.0  \n",
      "5        0.105263  0.101449  0.106061       1.0  \n",
      "6        0.052632  0.043478  0.075758       1.0  \n",
      "7        0.157895  0.159420  0.196970       1.0  \n",
      "8        0.131579  0.115942  0.106061       1.0  \n",
      "9        0.000000  0.028986  0.030303       0.0  \n",
      "10       0.000000  0.000000  0.000000       1.0  \n",
      "11       0.000000  0.028986  0.030303       1.0  \n",
      "12       0.052632  0.115942  0.121212       1.0  \n",
      "13       0.000000  0.101449  0.121212       1.0  \n",
      "14       0.000000  0.115942  0.136364       1.0  \n",
      "15       0.157895  0.115942  0.151515       1.0  \n",
      "16       0.131579  0.057971  0.075758       1.0  \n",
      "17       0.131579  0.086957  0.106061       1.0  \n",
      "18       0.131579  0.217391  0.242424       1.0  \n",
      "19       0.000000  0.057971  0.075758       1.0  \n",
      "20       0.000000  0.043478  0.030303       1.0  \n",
      "21       0.000000  0.000000  0.015152       1.0  \n",
      "22       0.000000  0.000000  0.000000       1.0  \n",
      "23       0.157895  0.188406  0.257576       1.0  \n",
      "24       0.000000  0.028986  0.000000       1.0  \n",
      "25       0.000000  0.072464  0.075758       1.0  \n",
      "26       0.131579  0.057971  0.075758       1.0  \n",
      "27       0.078947  0.115942  0.151515       1.0  \n",
      "28       0.157895  0.231884  0.181818       1.0  \n",
      "29       0.105263  0.159420  0.181818       1.0  \n",
      "...           ...       ...       ...       ...  \n",
      "15970    0.026316  0.173913  0.166667       1.0  \n",
      "15971    0.236842  0.115942  0.090909       1.0  \n",
      "15972    0.052632  0.173913  0.257576       1.0  \n",
      "15973    0.210526  0.115942  0.166667       1.0  \n",
      "15974    0.000000  0.086957  0.075758       1.0  \n",
      "15975    0.131579  0.188406  0.227273       1.0  \n",
      "15976    0.236842  0.130435  0.075758       1.0  \n",
      "15977    0.052632  0.057971  0.045455       1.0  \n",
      "15978    0.052632  0.231884  0.227273       0.0  \n",
      "15979    0.078947  0.173913  0.136364       0.0  \n",
      "15980    0.000000  0.014493  0.000000       1.0  \n",
      "15981    0.000000  0.101449  0.151515       0.0  \n",
      "15982    0.078947  0.072464  0.045455       0.0  \n",
      "15983    0.000000  0.000000  0.000000       0.0  \n",
      "15984    0.000000  0.000000  0.000000       0.0  \n",
      "15985    0.000000  0.000000  0.000000       1.0  \n",
      "15986    0.078947  0.014493  0.030303       1.0  \n",
      "15987    0.000000  0.000000  0.000000       1.0  \n",
      "15988    0.000000  0.000000  0.000000       0.0  \n",
      "15989    0.000000  0.000000  0.000000       0.0  \n",
      "15990    0.000000  0.000000  0.015152       0.0  \n",
      "15991    0.000000  0.000000  0.015152       1.0  \n",
      "15992    0.026316  0.043478  0.090909       0.0  \n",
      "15993    0.000000  0.057971  0.090909       0.0  \n",
      "15994    0.026316  0.028986  0.045455       1.0  \n",
      "15995    0.000000  0.014493  0.030303       1.0  \n",
      "15996    0.000000  0.028986  0.075758       1.0  \n",
      "15997    0.078947  0.101449  0.136364       1.0  \n",
      "15998    0.605263  0.304348  0.515152       1.0  \n",
      "15999    0.210526  0.159420  0.166667       1.0  \n",
      "\n",
      "[16000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "#We rename the columns back to their original names after losing them in the normalization process.\n",
    "cols_names={0:\"quality\",\n",
    "            1:\"bits\",\n",
    "            2:\"skip_parts\",\n",
    "            3:\"inter_other_parts\",\n",
    "            4:\"non_zero_pixels\",\n",
    "            5:\"frame_width\",\n",
    "            6:\"frame_height\",\n",
    "            7:\"sub_mean_1\",\n",
    "            8:\"sub_mean_2\",\n",
    "            9:\"sub_mean_3\",\n",
    "            10:\"sub_mean_4\",\n",
    "            11:\"sobel_h\",\n",
    "            12:\"sobel_v\",\n",
    "            13:\"relevant\"\n",
    "}\n",
    "df_preprocessed=df_preprocessed.rename(columns=cols_names)\n",
    "print(df_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           (0.5, 1.0]\n",
       "1           (0.5, 1.0]\n",
       "2           (0.5, 1.0]\n",
       "3           (0.5, 1.0]\n",
       "4           (0.5, 1.0]\n",
       "5           (0.5, 1.0]\n",
       "6           (0.5, 1.0]\n",
       "7           (0.5, 1.0]\n",
       "8           (0.5, 1.0]\n",
       "9        (-0.001, 0.5]\n",
       "10          (0.5, 1.0]\n",
       "11          (0.5, 1.0]\n",
       "12          (0.5, 1.0]\n",
       "13          (0.5, 1.0]\n",
       "14          (0.5, 1.0]\n",
       "15          (0.5, 1.0]\n",
       "16          (0.5, 1.0]\n",
       "17          (0.5, 1.0]\n",
       "18          (0.5, 1.0]\n",
       "19          (0.5, 1.0]\n",
       "20          (0.5, 1.0]\n",
       "21          (0.5, 1.0]\n",
       "22          (0.5, 1.0]\n",
       "23          (0.5, 1.0]\n",
       "24          (0.5, 1.0]\n",
       "25          (0.5, 1.0]\n",
       "26          (0.5, 1.0]\n",
       "27          (0.5, 1.0]\n",
       "28          (0.5, 1.0]\n",
       "29          (0.5, 1.0]\n",
       "             ...      \n",
       "15970       (0.5, 1.0]\n",
       "15971       (0.5, 1.0]\n",
       "15972       (0.5, 1.0]\n",
       "15973       (0.5, 1.0]\n",
       "15974       (0.5, 1.0]\n",
       "15975       (0.5, 1.0]\n",
       "15976       (0.5, 1.0]\n",
       "15977       (0.5, 1.0]\n",
       "15978    (-0.001, 0.5]\n",
       "15979    (-0.001, 0.5]\n",
       "15980       (0.5, 1.0]\n",
       "15981    (-0.001, 0.5]\n",
       "15982    (-0.001, 0.5]\n",
       "15983    (-0.001, 0.5]\n",
       "15984    (-0.001, 0.5]\n",
       "15985       (0.5, 1.0]\n",
       "15986       (0.5, 1.0]\n",
       "15987       (0.5, 1.0]\n",
       "15988    (-0.001, 0.5]\n",
       "15989    (-0.001, 0.5]\n",
       "15990    (-0.001, 0.5]\n",
       "15991       (0.5, 1.0]\n",
       "15992    (-0.001, 0.5]\n",
       "15993    (-0.001, 0.5]\n",
       "15994       (0.5, 1.0]\n",
       "15995       (0.5, 1.0]\n",
       "15996       (0.5, 1.0]\n",
       "15997       (0.5, 1.0]\n",
       "15998       (0.5, 1.0]\n",
       "15999       (0.5, 1.0]\n",
       "Name: relevant, Length: 16000, dtype: category\n",
       "Categories (2, interval[float64]): [(-0.001, 0.5] < (0.5, 1.0]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As a means to make a better model, we discretize our numerical variables to get ranges that should be more easily classified.\n",
    "pd.cut(df_preprocessed['quality'],5)\n",
    "pd.cut(df_preprocessed['bits'],5)\n",
    "pd.cut(df_preprocessed['skip_parts'],5)\n",
    "pd.cut(df_preprocessed['inter_other_parts'],5)\n",
    "pd.cut(df_preprocessed['non_zero_pixels'],5)\n",
    "pd.cut(df_preprocessed['frame_width'],5)\n",
    "pd.cut(df_preprocessed['frame_height'],5)\n",
    "pd.cut(df_preprocessed['sub_mean_1'],5)\n",
    "pd.cut(df_preprocessed['sub_mean_2'],5)\n",
    "pd.cut(df_preprocessed['sub_mean_3'],5)\n",
    "pd.cut(df_preprocessed['sub_mean_4'],5)\n",
    "pd.cut(df_preprocessed['sobel_h'],5)\n",
    "pd.cut(df_preprocessed['sobel_v'],5)\n",
    "pd.cut(df_preprocessed['relevant'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Earlier on, we mentioned that our class was very imbalanced. We will save its values for now and then remove the variable itself in order to make our samples.\n",
    "y=df_preprocessed.relevant\n",
    "X = df_preprocessed.drop('relevant', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we split our dataset into 70% training and 30% test.\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We do the upsampling process.\n",
    "X = pd.concat([x_train, y_train], axis=1)\n",
    "not_relevant = X[X.relevant==0]\n",
    "relevant = X[X.relevant==1]\n",
    "\n",
    "relevant_upsampled = resample(relevant,\n",
    "                          replace=True, #Sample with replacement\n",
    "                          n_samples=len(not_relevant), #Matching number in majority class\n",
    "                          random_state=27) #Reproducible results\n",
    "upsampled = pd.concat([not_relevant, relevant_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    2009\n",
       "0.0    2009\n",
       "Name: relevant, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the number of values for the relevant class, we see it is now even.\n",
    "upsampled.relevant.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = upsampled.relevant\n",
    "x_train = upsampled.drop('relevant', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21604166666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.18      1.00      0.31       835\n",
      "         1.0       1.00      0.05      0.10      3965\n",
      "\n",
      "    accuracy                           0.22      4800\n",
      "   macro avg       0.59      0.53      0.20      4800\n",
      "weighted avg       0.85      0.22      0.13      4800\n",
      "\n",
      "        Prediction 0  Prediction 1\n",
      "True 0           834             1\n",
      "True 1          3762           203\n"
     ]
    }
   ],
   "source": [
    "#LinearRegression model\n",
    "reg = LinearRegression().fit(x_train, y_train)\n",
    "prediction=reg.predict(x_test)\n",
    "y_test_array=y_test.to_numpy()\n",
    "for i in range(len(prediction)):\n",
    "    prediction[i]=int(prediction[i])\n",
    "    \n",
    "#Accuracy score and classification report.\n",
    "print(accuracy_score(y_test, prediction))\n",
    "print(classification_report(y_test, prediction))\n",
    "\n",
    "#Confusion matrix.\n",
    "conf_lr = pd.DataFrame(\n",
    "    confusion_matrix(y_test,prediction),\n",
    "    columns=['Prediction 0', 'Prediction 1'],\n",
    "    index=['True 0', 'True 1']\n",
    ")\n",
    "print(conf_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.18      1.00      0.30       835\n",
      "         1.0       1.00      0.01      0.02      3965\n",
      "\n",
      "    accuracy                           0.18      4800\n",
      "   macro avg       0.59      0.51      0.16      4800\n",
      "weighted avg       0.86      0.18      0.07      4800\n",
      "\n",
      "        Prediction 0  Prediction 1\n",
      "True 0           835             0\n",
      "True 1          3924            41\n"
     ]
    }
   ],
   "source": [
    "#RandomForestRegressor model.\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(x_train,y_train)\n",
    "y_pred_rf= rf.predict(x_test)\n",
    "y_test_array_rf=y_test.to_numpy()\n",
    "for i in range(len(y_pred_rf)):\n",
    "    y_pred_rf[i]=int(y_pred_rf[i])\n",
    "\n",
    "#Accuracy score and classification report.\n",
    "print(accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test,y_pred_rf))\n",
    "\n",
    "#Confusion matrix.\n",
    "conf_rf = pd.DataFrame(\n",
    "    confusion_matrix(y_test,y_pred_rf),\n",
    "    columns=['Prediction 0', 'Prediction 1'],\n",
    "    index=['True 0', 'True 1']\n",
    ")\n",
    "print(conf_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5339583333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      0.86      0.39       835\n",
      "         1.0       0.94      0.47      0.62      3965\n",
      "\n",
      "    accuracy                           0.53      4800\n",
      "   macro avg       0.60      0.66      0.51      4800\n",
      "weighted avg       0.82      0.53      0.58      4800\n",
      "\n",
      "        Predicted 0  Prediction 1\n",
      "True 0          714           121\n",
      "True 1         2116          1849\n"
     ]
    }
   ],
   "source": [
    "#NaiveBayes model.\n",
    "nb=GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_pred_nb_gaussian=nb.predict(x_test)\n",
    "\n",
    "#Accuracy score and classification report.\n",
    "print(accuracy_score(y_test, y_pred_nb_gaussian))\n",
    "print(classification_report(y_test,y_pred_nb_gaussian))\n",
    "\n",
    "#Confusion matrix.\n",
    "conf_nb=pd.DataFrame(\n",
    "    confusion_matrix(y_test,y_pred_nb_gaussian),\n",
    "    columns = ['Predicted 0', 'Prediction 1'],\n",
    "    index = ['True 0', 'True 1']\n",
    ")\n",
    "print(conf_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.653125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.30      0.77      0.44       835\n",
      "         1.0       0.93      0.63      0.75      3965\n",
      "\n",
      "    accuracy                           0.65      4800\n",
      "   macro avg       0.62      0.70      0.59      4800\n",
      "weighted avg       0.82      0.65      0.70      4800\n",
      "\n",
      "        Predicted 0  Prediction 1\n",
      "True 0          644           191\n",
      "True 1         1474          2491\n"
     ]
    }
   ],
   "source": [
    "#SVM model.\n",
    "svm = SVC(C=10.0)\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred_svm=svm.predict(x_test)\n",
    "\n",
    "#Accuracy score and classification report.\n",
    "print(accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test,y_pred_svm))\n",
    "\n",
    "#Confusion matrix.\n",
    "conf_svm=pd.DataFrame(\n",
    "    confusion_matrix(y_test,y_pred_svm),\n",
    "    columns = ['Predicted 0', 'Prediction 1'],\n",
    "    index = ['True 0', 'True 1']\n",
    ")\n",
    "print(conf_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.31      0.74      0.44       835\n",
      "         1.0       0.92      0.65      0.77      3965\n",
      "\n",
      "    accuracy                           0.67      4800\n",
      "   macro avg       0.62      0.70      0.60      4800\n",
      "weighted avg       0.82      0.67      0.71      4800\n",
      "\n",
      "        Predicted 0  Prediction 1\n",
      "True 0          644           191\n",
      "True 1         1474          2491\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression model\n",
    "clf = LogisticRegression(random_state=0).fit(x_train, y_train)\n",
    "y_pred_clf=clf.predict(x_test)\n",
    "\n",
    "#Accuracy score and classification report.\n",
    "print(accuracy_score(y_test, y_pred_clf))\n",
    "print(classification_report(y_test,y_pred_clf))\n",
    "\n",
    "#Confusion matrix.\n",
    "conf_clf=pd.DataFrame(\n",
    "    confusion_matrix(y_test,y_pred_clf),\n",
    "    columns = ['Predicted 0', 'Prediction 1'],\n",
    "    index = ['True 0', 'True 1']\n",
    ")\n",
    "print(conf_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.656875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      0.68      0.41       835\n",
      "         1.0       0.91      0.65      0.76      3965\n",
      "\n",
      "    accuracy                           0.66      4800\n",
      "   macro avg       0.60      0.67      0.58      4800\n",
      "weighted avg       0.80      0.66      0.70      4800\n",
      "\n",
      "        Predicted 0  Prediction 1\n",
      "True 0          569           266\n",
      "True 1         1381          2584\n"
     ]
    }
   ],
   "source": [
    "#KNN model.\n",
    "kne = KNeighborsClassifier(n_neighbors=3).fit(x_train, y_train)\n",
    "y_pred_kne=kne.predict(x_test)\n",
    "\n",
    "#Accuracy score and classification report.\n",
    "print(accuracy_score(y_test, y_pred_kne))\n",
    "print(classification_report(y_test,y_pred_kne))\n",
    "\n",
    "#Confusion matrix.\n",
    "conf_kne=pd.DataFrame(\n",
    "    confusion_matrix(y_test,y_pred_kne),\n",
    "    columns = ['Predicted 0', 'Prediction 1'],\n",
    "    index = ['True 0', 'True 1']\n",
    ")\n",
    "print(conf_kne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
