{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pickle\n",
    "pd.set_option('display.max_rows', 90)\n",
    "pd.set_option('display.max_columns', 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv',sep=',')\n",
    "data\n",
    "response_var = ['relevant']\n",
    "predictors = list(set(list(data.columns))-set(response_var)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = np.where(data[response_var].isnull()==True)[0] #where variable to predict is NaN\n",
    "data = data.drop(to_remove,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_impute = data.columns[data.isnull().any()[data.columns]==True].tolist() #columns to impute\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "data = pd.DataFrame(imp.fit_transform(data), columns=data.columns,index=data.index)\n",
    "\n",
    "data[response_var] = data[response_var].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality</th>\n",
       "      <th>bits</th>\n",
       "      <th>intra_parts</th>\n",
       "      <th>skip_parts</th>\n",
       "      <th>inter_16x16_parts</th>\n",
       "      <th>inter_4x4_parts</th>\n",
       "      <th>inter_other_parts</th>\n",
       "      <th>non_zero_pixels</th>\n",
       "      <th>frame_width</th>\n",
       "      <th>frame_height</th>\n",
       "      <th>movement_level</th>\n",
       "      <th>mean</th>\n",
       "      <th>sub_mean_1</th>\n",
       "      <th>sub_mean_2</th>\n",
       "      <th>sub_mean_3</th>\n",
       "      <th>sub_mean_4</th>\n",
       "      <th>var_sub_blocks</th>\n",
       "      <th>sobel_h</th>\n",
       "      <th>sobel_v</th>\n",
       "      <th>variance</th>\n",
       "      <th>block_movement_h</th>\n",
       "      <th>block_movement_v</th>\n",
       "      <th>var_movement_h</th>\n",
       "      <th>var_movement_v</th>\n",
       "      <th>cost_1</th>\n",
       "      <th>cost_2</th>\n",
       "      <th>relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449172</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.487923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.128320</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>0.120360</td>\n",
       "      <td>0.160287</td>\n",
       "      <td>0.004271</td>\n",
       "      <td>0.249583</td>\n",
       "      <td>0.260537</td>\n",
       "      <td>0.043311</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>0.013434</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363655</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.460145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.046240</td>\n",
       "      <td>0.056643</td>\n",
       "      <td>0.139796</td>\n",
       "      <td>0.135946</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.206966</td>\n",
       "      <td>0.213153</td>\n",
       "      <td>0.023749</td>\n",
       "      <td>0.005724</td>\n",
       "      <td>0.010169</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.020709</td>\n",
       "      <td>0.019720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413121</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.061328</td>\n",
       "      <td>0.056131</td>\n",
       "      <td>0.184563</td>\n",
       "      <td>0.187153</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.218103</td>\n",
       "      <td>0.208956</td>\n",
       "      <td>0.027996</td>\n",
       "      <td>0.009314</td>\n",
       "      <td>0.026124</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.011636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518340</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.508454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>0.083008</td>\n",
       "      <td>0.078686</td>\n",
       "      <td>0.299267</td>\n",
       "      <td>0.163317</td>\n",
       "      <td>0.011710</td>\n",
       "      <td>0.311674</td>\n",
       "      <td>0.436763</td>\n",
       "      <td>0.139986</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.013228</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.050577</td>\n",
       "      <td>0.044369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229092</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.201691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.094141</td>\n",
       "      <td>0.064230</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.043531</td>\n",
       "      <td>0.007217</td>\n",
       "      <td>0.171143</td>\n",
       "      <td>0.214952</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.009532</td>\n",
       "      <td>0.023934</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.032599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013834</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.959529</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.020552</td>\n",
       "      <td>0.035962</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>0.012807</td>\n",
       "      <td>0.071098</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.014257</td>\n",
       "      <td>0.043937</td>\n",
       "      <td>0.040965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020960</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.959529</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.064844</td>\n",
       "      <td>0.024195</td>\n",
       "      <td>0.030588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>0.040810</td>\n",
       "      <td>0.088201</td>\n",
       "      <td>0.007544</td>\n",
       "      <td>0.011449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098044</td>\n",
       "      <td>0.083378</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.029554</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.018116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.959529</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.108594</td>\n",
       "      <td>0.064794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080497</td>\n",
       "      <td>0.008794</td>\n",
       "      <td>0.108729</td>\n",
       "      <td>0.135351</td>\n",
       "      <td>0.025153</td>\n",
       "      <td>0.026002</td>\n",
       "      <td>0.086640</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.011933</td>\n",
       "      <td>0.048489</td>\n",
       "      <td>0.038194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070216</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.045894</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.959529</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>0.090430</td>\n",
       "      <td>0.082274</td>\n",
       "      <td>0.067389</td>\n",
       "      <td>0.611150</td>\n",
       "      <td>0.056167</td>\n",
       "      <td>0.307822</td>\n",
       "      <td>0.515049</td>\n",
       "      <td>0.153775</td>\n",
       "      <td>0.028621</td>\n",
       "      <td>0.157903</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.023545</td>\n",
       "      <td>0.293814</td>\n",
       "      <td>0.329225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047370</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.959529</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.069922</td>\n",
       "      <td>0.029988</td>\n",
       "      <td>0.124900</td>\n",
       "      <td>0.211191</td>\n",
       "      <td>0.003973</td>\n",
       "      <td>0.157862</td>\n",
       "      <td>0.178157</td>\n",
       "      <td>0.019359</td>\n",
       "      <td>0.021927</td>\n",
       "      <td>0.125331</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.026277</td>\n",
       "      <td>0.403470</td>\n",
       "      <td>0.413001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15998 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       quality      bits  intra_parts  skip_parts  inter_16x16_parts  \\\n",
       "0          0.0  0.449172         0.00        0.00               0.25   \n",
       "1          0.0  0.363655         0.00        0.50               0.00   \n",
       "2          0.0  0.413121         0.00        0.00               0.00   \n",
       "3          0.0  0.518340         0.00        0.00               0.00   \n",
       "4          0.0  0.229092         0.00        0.00               0.25   \n",
       "...        ...       ...          ...         ...                ...   \n",
       "15995      1.0  0.013834         0.25        0.25               0.25   \n",
       "15996      1.0  0.020960         0.50        0.00               0.00   \n",
       "15997      1.0  0.029554         0.25        0.25               0.00   \n",
       "15998      1.0  0.070216         0.25        0.00               0.50   \n",
       "15999      1.0  0.047370         0.50        0.00               0.00   \n",
       "\n",
       "       inter_4x4_parts  inter_other_parts  non_zero_pixels  frame_width  \\\n",
       "0             0.090909           0.777778         0.487923          0.0   \n",
       "1             0.090909           0.296296         0.460145          0.0   \n",
       "2             0.000000           0.296296         0.555556          0.0   \n",
       "3             0.545455           0.740741         0.508454          0.0   \n",
       "4             0.090909           0.296296         0.201691          0.0   \n",
       "...                ...                ...              ...          ...   \n",
       "15995         0.272727           0.037037         0.003623          1.0   \n",
       "15996         0.545455           0.074074         0.009662          1.0   \n",
       "15997         0.000000           0.148148         0.018116          1.0   \n",
       "15998         0.181818           0.074074         0.045894          1.0   \n",
       "15999         0.000000           0.148148         0.028986          1.0   \n",
       "\n",
       "       frame_height  movement_level      mean  sub_mean_1  sub_mean_2  \\\n",
       "0               0.0        0.000874  0.003046    0.128320    0.056900   \n",
       "1               0.0        0.000874  0.002296    0.046240    0.056643   \n",
       "2               0.0        0.000874  0.002906    0.061328    0.056131   \n",
       "3               0.0        0.000874  0.003837    0.083008    0.078686   \n",
       "4               0.0        0.000874  0.001631    0.094141    0.064230   \n",
       "...             ...             ...       ...         ...         ...   \n",
       "15995           1.0        0.959529  0.000381    0.000000    0.000000   \n",
       "15996           1.0        0.959529  0.000973    0.064844    0.024195   \n",
       "15997           1.0        0.959529  0.001910    0.108594    0.064794   \n",
       "15998           1.0        0.959529  0.004614    0.090430    0.082274   \n",
       "15999           1.0        0.959529  0.002529    0.069922    0.029988   \n",
       "\n",
       "       sub_mean_3  sub_mean_4  var_sub_blocks   sobel_h   sobel_v  variance  \\\n",
       "0        0.120360    0.160287        0.004271  0.249583  0.260537  0.043311   \n",
       "1        0.139796    0.135946        0.001261  0.206966  0.213153  0.023749   \n",
       "2        0.184563    0.187153        0.003220  0.218103  0.208956  0.027996   \n",
       "3        0.299267    0.163317        0.011710  0.311674  0.436763  0.139986   \n",
       "4        0.003903    0.043531        0.007217  0.171143  0.214952  0.086600   \n",
       "...           ...         ...             ...       ...       ...       ...   \n",
       "15995    0.068185    0.000000        0.001867  0.020552  0.035962  0.003290   \n",
       "15996    0.030588    0.000000        0.003198  0.040810  0.088201  0.007544   \n",
       "15997    0.000000    0.080497        0.008794  0.108729  0.135351  0.025153   \n",
       "15998    0.067389    0.611150        0.056167  0.307822  0.515049  0.153775   \n",
       "15999    0.124900    0.211191        0.003973  0.157862  0.178157  0.019359   \n",
       "\n",
       "       block_movement_h  block_movement_v  var_movement_h  var_movement_v  \\\n",
       "0              0.008756          0.013434        0.000055        0.000125   \n",
       "1              0.005724          0.010169        0.000032        0.000097   \n",
       "2              0.009314          0.026124        0.000008        0.000054   \n",
       "3              0.006452          0.013228        0.000133        0.000507   \n",
       "4              0.009532          0.023934        0.000114        0.000216   \n",
       "...                 ...               ...             ...             ...   \n",
       "15995          0.012807          0.071098        0.000491        0.014257   \n",
       "15996          0.011449          0.000000        0.001048        0.000000   \n",
       "15997          0.026002          0.086640        0.001139        0.011933   \n",
       "15998          0.028621          0.157903        0.000617        0.023545   \n",
       "15999          0.021927          0.125331        0.000790        0.026277   \n",
       "\n",
       "         cost_1    cost_2  relevant  \n",
       "0      0.000000  0.000000         1  \n",
       "1      0.020709  0.019720         1  \n",
       "2      0.011990  0.011636         1  \n",
       "3      0.050577  0.044369         1  \n",
       "4      0.035407  0.032599         1  \n",
       "...         ...       ...       ...  \n",
       "15995  0.043937  0.040965         1  \n",
       "15996  0.098044  0.083378         1  \n",
       "15997  0.048489  0.038194         1  \n",
       "15998  0.293814  0.329225         1  \n",
       "15999  0.403470  0.413001         1  \n",
       "\n",
       "[15998 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[predictors] = (data[predictors]-data[predictors].min())/(data[predictors].max()-data[predictors].min())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = data.index.tolist()\n",
    "train = np.random.choice(index, np.round(len(index)*2/3).astype(int), replace=False)\n",
    "test =[ele for ele in index if ele not in train]\n",
    "\n",
    "x_train = data.loc[train][predictors]\n",
    "y_train = np.ravel(data.loc[train][response_var])\n",
    "x_test = data.loc[test][predictors]\n",
    "y_test = np.ravel(data.loc[test][response_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  33,   38],\n",
       "       [ 879, 4383]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(x_train,y_train)\n",
    "pred_NB = Naive.predict(x_test)\n",
    "\n",
    "confusion_matrix(pred_NB,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 207,  170],\n",
       "       [ 705, 4251]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=RandomForestClassifier(n_estimators=1000,criterion='gini')\n",
    "\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "pred_RF = clf.predict(x_test)\n",
    "\n",
    "confusion_matrix(pred_RF,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10665/10665 [==============================] - 1s 55us/step - loss: 0.1625 - accuracy: 0.6092\n",
      "Epoch 2/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1552 - accuracy: 0.6237\n",
      "Epoch 3/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1535 - accuracy: 0.6110\n",
      "Epoch 4/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1532 - accuracy: 0.6303\n",
      "Epoch 5/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.1514 - accuracy: 0.6321\n",
      "Epoch 6/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1519 - accuracy: 0.6444\n",
      "Epoch 7/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1506 - accuracy: 0.6326\n",
      "Epoch 8/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1505 - accuracy: 0.6405\n",
      "Epoch 9/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1490 - accuracy: 0.6453\n",
      "Epoch 10/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1490 - accuracy: 0.6338\n",
      "Epoch 11/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1482 - accuracy: 0.6368\n",
      "Epoch 12/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1473 - accuracy: 0.6564\n",
      "Epoch 13/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1494 - accuracy: 0.6654\n",
      "Epoch 14/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1464 - accuracy: 0.6521\n",
      "Epoch 15/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1457 - accuracy: 0.6519\n",
      "Epoch 16/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1449 - accuracy: 0.6465\n",
      "Epoch 17/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1444 - accuracy: 0.6565\n",
      "Epoch 18/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1453 - accuracy: 0.6489\n",
      "Epoch 19/500\n",
      "10665/10665 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.65 - 0s 22us/step - loss: 0.1439 - accuracy: 0.6503\n",
      "Epoch 20/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1440 - accuracy: 0.6487\n",
      "Epoch 21/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1427 - accuracy: 0.6484\n",
      "Epoch 22/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1422 - accuracy: 0.6605\n",
      "Epoch 23/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1418 - accuracy: 0.6581\n",
      "Epoch 24/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1420 - accuracy: 0.6508\n",
      "Epoch 25/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1410 - accuracy: 0.6535\n",
      "Epoch 26/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1396 - accuracy: 0.6529\n",
      "Epoch 27/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1400 - accuracy: 0.6513\n",
      "Epoch 28/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1394 - accuracy: 0.6638\n",
      "Epoch 29/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1403 - accuracy: 0.6683\n",
      "Epoch 30/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1381 - accuracy: 0.6515\n",
      "Epoch 31/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1368 - accuracy: 0.6674\n",
      "Epoch 32/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1363 - accuracy: 0.6627\n",
      "Epoch 33/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1371 - accuracy: 0.6602\n",
      "Epoch 34/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1352 - accuracy: 0.6587\n",
      "Epoch 35/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1339 - accuracy: 0.6514\n",
      "Epoch 36/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1344 - accuracy: 0.6640\n",
      "Epoch 37/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1347 - accuracy: 0.6626\n",
      "Epoch 38/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1345 - accuracy: 0.6529\n",
      "Epoch 39/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1335 - accuracy: 0.6669\n",
      "Epoch 40/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1321 - accuracy: 0.6613\n",
      "Epoch 41/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1323 - accuracy: 0.6691\n",
      "Epoch 42/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1310 - accuracy: 0.6654\n",
      "Epoch 43/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1317 - accuracy: 0.6693\n",
      "Epoch 44/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1310 - accuracy: 0.6679\n",
      "Epoch 45/500\n",
      "10665/10665 [==============================] - 0s 21us/step - loss: 0.1302 - accuracy: 0.6512\n",
      "Epoch 46/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1291 - accuracy: 0.6627\n",
      "Epoch 47/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1295 - accuracy: 0.6521\n",
      "Epoch 48/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.1292 - accuracy: 0.6768\n",
      "Epoch 49/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1279 - accuracy: 0.6774\n",
      "Epoch 50/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1290 - accuracy: 0.6724\n",
      "Epoch 51/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1261 - accuracy: 0.6748\n",
      "Epoch 52/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1259 - accuracy: 0.6728\n",
      "Epoch 53/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1262 - accuracy: 0.6758\n",
      "Epoch 54/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1255 - accuracy: 0.6746\n",
      "Epoch 55/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1244 - accuracy: 0.6774\n",
      "Epoch 56/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1255 - accuracy: 0.6763\n",
      "Epoch 57/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1234 - accuracy: 0.6701\n",
      "Epoch 58/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1236 - accuracy: 0.6734\n",
      "Epoch 59/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1207 - accuracy: 0.6839\n",
      "Epoch 60/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1210 - accuracy: 0.6812\n",
      "Epoch 61/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1211 - accuracy: 0.6871\n",
      "Epoch 62/500\n",
      "10665/10665 [==============================] - 0s 32us/step - loss: 0.1220 - accuracy: 0.6758\n",
      "Epoch 63/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1221 - accuracy: 0.6820\n",
      "Epoch 64/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1210 - accuracy: 0.6913\n",
      "Epoch 65/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1190 - accuracy: 0.6837\n",
      "Epoch 66/500\n",
      "10665/10665 [==============================] - 0s 26us/step - loss: 0.1202 - accuracy: 0.6908\n",
      "Epoch 67/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.1202 - accuracy: 0.6775\n",
      "Epoch 68/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1170 - accuracy: 0.6955\n",
      "Epoch 69/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1158 - accuracy: 0.6979\n",
      "Epoch 70/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.1148 - accuracy: 0.7029\n",
      "Epoch 71/500\n",
      "10665/10665 [==============================] - 0s 27us/step - loss: 0.1190 - accuracy: 0.6853\n",
      "Epoch 72/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1148 - accuracy: 0.7006\n",
      "Epoch 73/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1137 - accuracy: 0.7030\n",
      "Epoch 74/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1158 - accuracy: 0.6909\n",
      "Epoch 75/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1197 - accuracy: 0.6918\n",
      "Epoch 76/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1166 - accuracy: 0.7000\n",
      "Epoch 77/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1155 - accuracy: 0.7014\n",
      "Epoch 78/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1115 - accuracy: 0.7112\n",
      "Epoch 79/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1110 - accuracy: 0.7054\n",
      "Epoch 80/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1112 - accuracy: 0.7142\n",
      "Epoch 81/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1112 - accuracy: 0.7005\n",
      "Epoch 82/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1115 - accuracy: 0.7094\n",
      "Epoch 83/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1104 - accuracy: 0.7024\n",
      "Epoch 84/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1085 - accuracy: 0.7136\n",
      "Epoch 85/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1069 - accuracy: 0.7242\n",
      "Epoch 86/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1059 - accuracy: 0.7212\n",
      "Epoch 87/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1094 - accuracy: 0.7131\n",
      "Epoch 88/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1090 - accuracy: 0.7139\n",
      "Epoch 89/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1080 - accuracy: 0.7170\n",
      "Epoch 90/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1084 - accuracy: 0.7200\n",
      "Epoch 91/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1065 - accuracy: 0.7193\n",
      "Epoch 92/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1063 - accuracy: 0.7116\n",
      "Epoch 93/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1051 - accuracy: 0.7315\n",
      "Epoch 94/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1035 - accuracy: 0.7255\n",
      "Epoch 95/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1027 - accuracy: 0.7307\n",
      "Epoch 96/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1046 - accuracy: 0.7248\n",
      "Epoch 97/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1011 - accuracy: 0.7314\n",
      "Epoch 98/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1033 - accuracy: 0.7277\n",
      "Epoch 99/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1019 - accuracy: 0.7256\n",
      "Epoch 100/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1035 - accuracy: 0.7297\n",
      "Epoch 101/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1051 - accuracy: 0.7238\n",
      "Epoch 102/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1038 - accuracy: 0.7285\n",
      "Epoch 103/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1012 - accuracy: 0.7414\n",
      "Epoch 104/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.1039 - accuracy: 0.7299\n",
      "Epoch 105/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1020 - accuracy: 0.7324\n",
      "Epoch 106/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0979 - accuracy: 0.7425\n",
      "Epoch 107/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.1043 - accuracy: 0.7276\n",
      "Epoch 108/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0990 - accuracy: 0.7382\n",
      "Epoch 109/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0980 - accuracy: 0.7470\n",
      "Epoch 110/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0996 - accuracy: 0.7405\n",
      "Epoch 111/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0998 - accuracy: 0.7382\n",
      "Epoch 112/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0983 - accuracy: 0.7436\n",
      "Epoch 113/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0973 - accuracy: 0.7505\n",
      "Epoch 114/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0954 - accuracy: 0.7531\n",
      "Epoch 115/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0953 - accuracy: 0.7511\n",
      "Epoch 116/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0974 - accuracy: 0.7471\n",
      "Epoch 117/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0996 - accuracy: 0.7353\n",
      "Epoch 118/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0985 - accuracy: 0.7467 0s - loss: 0.0967 - accuracy: 0.\n",
      "Epoch 119/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0937 - accuracy: 0.7481\n",
      "Epoch 120/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0905 - accuracy: 0.7628\n",
      "Epoch 121/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0976 - accuracy: 0.7475\n",
      "Epoch 122/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0910 - accuracy: 0.7584\n",
      "Epoch 123/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0974 - accuracy: 0.7569\n",
      "Epoch 124/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0910 - accuracy: 0.7622\n",
      "Epoch 125/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0930 - accuracy: 0.7611\n",
      "Epoch 126/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0979 - accuracy: 0.7489\n",
      "Epoch 127/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0923 - accuracy: 0.7652\n",
      "Epoch 128/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0960 - accuracy: 0.7517\n",
      "Epoch 129/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0895 - accuracy: 0.7694\n",
      "Epoch 130/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0897 - accuracy: 0.7667\n",
      "Epoch 131/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0932 - accuracy: 0.7541\n",
      "Epoch 132/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0974 - accuracy: 0.7517\n",
      "Epoch 133/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0943 - accuracy: 0.7560\n",
      "Epoch 134/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0934 - accuracy: 0.7606\n",
      "Epoch 135/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0914 - accuracy: 0.7609\n",
      "Epoch 136/500\n",
      "10665/10665 [==============================] - 0s 26us/step - loss: 0.0892 - accuracy: 0.7712\n",
      "Epoch 137/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0894 - accuracy: 0.7738\n",
      "Epoch 138/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0904 - accuracy: 0.7670\n",
      "Epoch 139/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0931 - accuracy: 0.7648\n",
      "Epoch 140/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0873 - accuracy: 0.7802\n",
      "Epoch 141/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0877 - accuracy: 0.7792\n",
      "Epoch 142/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0874 - accuracy: 0.7738\n",
      "Epoch 143/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0931 - accuracy: 0.7632\n",
      "Epoch 144/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0893 - accuracy: 0.7720\n",
      "Epoch 145/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0918 - accuracy: 0.7723\n",
      "Epoch 146/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0857 - accuracy: 0.7787\n",
      "Epoch 147/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0903 - accuracy: 0.7681\n",
      "Epoch 148/500\n",
      "10665/10665 [==============================] - 0s 26us/step - loss: 0.0926 - accuracy: 0.7591\n",
      "Epoch 149/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0871 - accuracy: 0.7793\n",
      "Epoch 150/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0920 - accuracy: 0.7675\n",
      "Epoch 151/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0863 - accuracy: 0.7816\n",
      "Epoch 152/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0901 - accuracy: 0.7703\n",
      "Epoch 153/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0859 - accuracy: 0.7785\n",
      "Epoch 154/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0877 - accuracy: 0.7767\n",
      "Epoch 155/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0856 - accuracy: 0.7822\n",
      "Epoch 156/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0850 - accuracy: 0.7858\n",
      "Epoch 157/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0847 - accuracy: 0.7806\n",
      "Epoch 158/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0946 - accuracy: 0.7586\n",
      "Epoch 159/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0861 - accuracy: 0.7771\n",
      "Epoch 160/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0843 - accuracy: 0.7858\n",
      "Epoch 161/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0810 - accuracy: 0.7911\n",
      "Epoch 162/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0911 - accuracy: 0.7720\n",
      "Epoch 163/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0830 - accuracy: 0.7852\n",
      "Epoch 164/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0901 - accuracy: 0.7773\n",
      "Epoch 165/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0861 - accuracy: 0.7887\n",
      "Epoch 166/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0832 - accuracy: 0.7908\n",
      "Epoch 167/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0860 - accuracy: 0.7871\n",
      "Epoch 168/500\n",
      "10665/10665 [==============================] - 0s 29us/step - loss: 0.0874 - accuracy: 0.7767\n",
      "Epoch 169/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0853 - accuracy: 0.7800\n",
      "Epoch 170/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0811 - accuracy: 0.7911\n",
      "Epoch 171/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0816 - accuracy: 0.7909\n",
      "Epoch 172/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0816 - accuracy: 0.7929\n",
      "Epoch 173/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0826 - accuracy: 0.7930\n",
      "Epoch 174/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0841 - accuracy: 0.7872\n",
      "Epoch 175/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0801 - accuracy: 0.7965\n",
      "Epoch 176/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0806 - accuracy: 0.7993\n",
      "Epoch 177/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0843 - accuracy: 0.7874\n",
      "Epoch 178/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0805 - accuracy: 0.8015\n",
      "Epoch 179/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0860 - accuracy: 0.7873\n",
      "Epoch 180/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0886 - accuracy: 0.7796\n",
      "Epoch 181/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0910 - accuracy: 0.7798\n",
      "Epoch 182/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0858 - accuracy: 0.7854\n",
      "Epoch 183/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0809 - accuracy: 0.7937\n",
      "Epoch 184/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0789 - accuracy: 0.8002\n",
      "Epoch 185/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0855 - accuracy: 0.7878\n",
      "Epoch 186/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0811 - accuracy: 0.7958\n",
      "Epoch 187/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0872 - accuracy: 0.7775\n",
      "Epoch 188/500\n",
      "10665/10665 [==============================] - 0s 26us/step - loss: 0.0828 - accuracy: 0.7947\n",
      "Epoch 189/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0787 - accuracy: 0.8020\n",
      "Epoch 190/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0814 - accuracy: 0.7980\n",
      "Epoch 191/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0765 - accuracy: 0.8107\n",
      "Epoch 192/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0791 - accuracy: 0.8022\n",
      "Epoch 193/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0806 - accuracy: 0.7976\n",
      "Epoch 194/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0817 - accuracy: 0.7986\n",
      "Epoch 195/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0807 - accuracy: 0.7993\n",
      "Epoch 196/500\n",
      "10665/10665 [==============================] - 0s 26us/step - loss: 0.0830 - accuracy: 0.7939\n",
      "Epoch 197/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0789 - accuracy: 0.7986\n",
      "Epoch 198/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0801 - accuracy: 0.8029\n",
      "Epoch 199/500\n",
      "10665/10665 [==============================] - 0s 29us/step - loss: 0.0779 - accuracy: 0.8023\n",
      "Epoch 200/500\n",
      "10665/10665 [==============================] - 0s 26us/step - loss: 0.0841 - accuracy: 0.7965\n",
      "Epoch 201/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0785 - accuracy: 0.8064\n",
      "Epoch 202/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0733 - accuracy: 0.8139\n",
      "Epoch 203/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0787 - accuracy: 0.8018\n",
      "Epoch 204/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0828 - accuracy: 0.7988\n",
      "Epoch 205/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0867 - accuracy: 0.7871\n",
      "Epoch 206/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0788 - accuracy: 0.8043\n",
      "Epoch 207/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0799 - accuracy: 0.8010\n",
      "Epoch 208/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0793 - accuracy: 0.7997\n",
      "Epoch 209/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0749 - accuracy: 0.8088\n",
      "Epoch 210/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0750 - accuracy: 0.8138\n",
      "Epoch 211/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0791 - accuracy: 0.8038\n",
      "Epoch 212/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0830 - accuracy: 0.7952\n",
      "Epoch 213/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0786 - accuracy: 0.8012\n",
      "Epoch 214/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0891 - accuracy: 0.7899\n",
      "Epoch 215/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0740 - accuracy: 0.8177\n",
      "Epoch 216/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0740 - accuracy: 0.8177\n",
      "Epoch 217/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0768 - accuracy: 0.8083\n",
      "Epoch 218/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0797 - accuracy: 0.8043\n",
      "Epoch 219/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0733 - accuracy: 0.8186\n",
      "Epoch 220/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0791 - accuracy: 0.8040\n",
      "Epoch 221/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0724 - accuracy: 0.8152\n",
      "Epoch 222/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0747 - accuracy: 0.8158\n",
      "Epoch 223/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0747 - accuracy: 0.8128\n",
      "Epoch 224/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0733 - accuracy: 0.8130\n",
      "Epoch 225/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0805 - accuracy: 0.8067\n",
      "Epoch 226/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0730 - accuracy: 0.8176\n",
      "Epoch 227/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0747 - accuracy: 0.8150\n",
      "Epoch 228/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0830 - accuracy: 0.7963\n",
      "Epoch 229/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0760 - accuracy: 0.8100\n",
      "Epoch 230/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0704 - accuracy: 0.8188\n",
      "Epoch 231/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0700 - accuracy: 0.8218\n",
      "Epoch 232/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0724 - accuracy: 0.8192\n",
      "Epoch 233/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0800 - accuracy: 0.8079\n",
      "Epoch 234/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0831 - accuracy: 0.7962\n",
      "Epoch 235/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0765 - accuracy: 0.8117\n",
      "Epoch 236/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0776 - accuracy: 0.8118\n",
      "Epoch 237/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0873 - accuracy: 0.7889\n",
      "Epoch 238/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0800 - accuracy: 0.7997\n",
      "Epoch 239/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0709 - accuracy: 0.8187\n",
      "Epoch 240/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0753 - accuracy: 0.8119\n",
      "Epoch 241/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0694 - accuracy: 0.8191\n",
      "Epoch 242/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0740 - accuracy: 0.8149\n",
      "Epoch 243/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0753 - accuracy: 0.8207\n",
      "Epoch 244/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0810 - accuracy: 0.7949\n",
      "Epoch 245/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0716 - accuracy: 0.8189\n",
      "Epoch 246/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0785 - accuracy: 0.8072\n",
      "Epoch 247/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0728 - accuracy: 0.8248\n",
      "Epoch 248/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0746 - accuracy: 0.8179\n",
      "Epoch 249/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0715 - accuracy: 0.8207\n",
      "Epoch 250/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0766 - accuracy: 0.8133\n",
      "Epoch 251/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0738 - accuracy: 0.8136\n",
      "Epoch 252/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0695 - accuracy: 0.8278\n",
      "Epoch 253/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0773 - accuracy: 0.8109\n",
      "Epoch 254/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0703 - accuracy: 0.8257\n",
      "Epoch 255/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0716 - accuracy: 0.8205\n",
      "Epoch 256/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0784 - accuracy: 0.8087\n",
      "Epoch 257/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0731 - accuracy: 0.8215\n",
      "Epoch 258/500\n",
      "10665/10665 [==============================] - 0s 26us/step - loss: 0.0679 - accuracy: 0.8308\n",
      "Epoch 259/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0700 - accuracy: 0.8215\n",
      "Epoch 260/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0799 - accuracy: 0.8061\n",
      "Epoch 261/500\n",
      "10665/10665 [==============================] - 0s 31us/step - loss: 0.0747 - accuracy: 0.8171\n",
      "Epoch 262/500\n",
      "10665/10665 [==============================] - 0s 26us/step - loss: 0.0709 - accuracy: 0.8251\n",
      "Epoch 263/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0755 - accuracy: 0.8162\n",
      "Epoch 264/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0726 - accuracy: 0.8199\n",
      "Epoch 265/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0698 - accuracy: 0.8252\n",
      "Epoch 266/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0836 - accuracy: 0.7971\n",
      "Epoch 267/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0777 - accuracy: 0.8137\n",
      "Epoch 268/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0700 - accuracy: 0.8245\n",
      "Epoch 269/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0670 - accuracy: 0.8331\n",
      "Epoch 270/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0702 - accuracy: 0.8306\n",
      "Epoch 271/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0882 - accuracy: 0.7943\n",
      "Epoch 272/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0722 - accuracy: 0.8207\n",
      "Epoch 273/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0680 - accuracy: 0.8300\n",
      "Epoch 274/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0665 - accuracy: 0.8327\n",
      "Epoch 275/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0685 - accuracy: 0.8345\n",
      "Epoch 276/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0711 - accuracy: 0.8279\n",
      "Epoch 277/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0728 - accuracy: 0.8225\n",
      "Epoch 278/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0692 - accuracy: 0.8332\n",
      "Epoch 279/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0788 - accuracy: 0.8102\n",
      "Epoch 280/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0721 - accuracy: 0.8191\n",
      "Epoch 281/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0656 - accuracy: 0.8338\n",
      "Epoch 282/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0655 - accuracy: 0.8351\n",
      "Epoch 283/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0658 - accuracy: 0.8406\n",
      "Epoch 284/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0699 - accuracy: 0.8293\n",
      "Epoch 285/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0781 - accuracy: 0.8130\n",
      "Epoch 286/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0787 - accuracy: 0.8085\n",
      "Epoch 287/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0704 - accuracy: 0.8278\n",
      "Epoch 288/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0791 - accuracy: 0.8135\n",
      "Epoch 289/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0675 - accuracy: 0.8306\n",
      "Epoch 290/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0614 - accuracy: 0.8433\n",
      "Epoch 291/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0717 - accuracy: 0.8268\n",
      "Epoch 292/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0695 - accuracy: 0.8324\n",
      "Epoch 293/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0660 - accuracy: 0.8388\n",
      "Epoch 294/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0716 - accuracy: 0.8299\n",
      "Epoch 295/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0673 - accuracy: 0.8320\n",
      "Epoch 296/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0699 - accuracy: 0.8295\n",
      "Epoch 297/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0675 - accuracy: 0.8336\n",
      "Epoch 298/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0650 - accuracy: 0.8374\n",
      "Epoch 299/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0717 - accuracy: 0.8308\n",
      "Epoch 300/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0675 - accuracy: 0.8323\n",
      "Epoch 301/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0664 - accuracy: 0.8373\n",
      "Epoch 302/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0675 - accuracy: 0.8368\n",
      "Epoch 303/500\n",
      "10665/10665 [==============================] - 0s 27us/step - loss: 0.0678 - accuracy: 0.8381\n",
      "Epoch 304/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0709 - accuracy: 0.8321\n",
      "Epoch 305/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0763 - accuracy: 0.8216\n",
      "Epoch 306/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0678 - accuracy: 0.8330\n",
      "Epoch 307/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0642 - accuracy: 0.8413\n",
      "Epoch 308/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0667 - accuracy: 0.8358\n",
      "Epoch 309/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0672 - accuracy: 0.8387\n",
      "Epoch 310/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0671 - accuracy: 0.8429\n",
      "Epoch 311/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0687 - accuracy: 0.8300\n",
      "Epoch 312/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0674 - accuracy: 0.8344\n",
      "Epoch 313/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0787 - accuracy: 0.8208\n",
      "Epoch 314/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0689 - accuracy: 0.8352\n",
      "Epoch 315/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0644 - accuracy: 0.8387\n",
      "Epoch 316/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0641 - accuracy: 0.8394\n",
      "Epoch 317/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0670 - accuracy: 0.8373\n",
      "Epoch 318/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0649 - accuracy: 0.8392\n",
      "Epoch 319/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0628 - accuracy: 0.8446\n",
      "Epoch 320/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0679 - accuracy: 0.8372\n",
      "Epoch 321/500\n",
      "10665/10665 [==============================] - 0s 26us/step - loss: 0.0800 - accuracy: 0.8196\n",
      "Epoch 322/500\n",
      "10665/10665 [==============================] - 0s 26us/step - loss: 0.0744 - accuracy: 0.8195\n",
      "Epoch 323/500\n",
      "10665/10665 [==============================] - 0s 27us/step - loss: 0.0667 - accuracy: 0.8348\n",
      "Epoch 324/500\n",
      "10665/10665 [==============================] - 0s 30us/step - loss: 0.0592 - accuracy: 0.8519\n",
      "Epoch 325/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0589 - accuracy: 0.8538\n",
      "Epoch 326/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0597 - accuracy: 0.8538\n",
      "Epoch 327/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0699 - accuracy: 0.8330\n",
      "Epoch 328/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0671 - accuracy: 0.8394\n",
      "Epoch 329/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0688 - accuracy: 0.8395\n",
      "Epoch 330/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0758 - accuracy: 0.8213\n",
      "Epoch 331/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0626 - accuracy: 0.8450\n",
      "Epoch 332/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0619 - accuracy: 0.8450\n",
      "Epoch 333/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0620 - accuracy: 0.8464\n",
      "Epoch 334/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0671 - accuracy: 0.8418\n",
      "Epoch 335/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0657 - accuracy: 0.8395\n",
      "Epoch 336/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0609 - accuracy: 0.8474\n",
      "Epoch 337/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0621 - accuracy: 0.8459\n",
      "Epoch 338/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0630 - accuracy: 0.8437\n",
      "Epoch 339/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0587 - accuracy: 0.8533\n",
      "Epoch 340/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0666 - accuracy: 0.8429\n",
      "Epoch 341/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0707 - accuracy: 0.8325\n",
      "Epoch 342/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0676 - accuracy: 0.8355\n",
      "Epoch 343/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0685 - accuracy: 0.8349\n",
      "Epoch 344/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0668 - accuracy: 0.8398\n",
      "Epoch 345/500\n",
      "10665/10665 [==============================] - 0s 28us/step - loss: 0.0628 - accuracy: 0.8442\n",
      "Epoch 346/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0672 - accuracy: 0.8414\n",
      "Epoch 347/500\n",
      "10665/10665 [==============================] - 0s 27us/step - loss: 0.0792 - accuracy: 0.8135\n",
      "Epoch 348/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0665 - accuracy: 0.8357\n",
      "Epoch 349/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0628 - accuracy: 0.8487\n",
      "Epoch 350/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0618 - accuracy: 0.8499\n",
      "Epoch 351/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0594 - accuracy: 0.8534\n",
      "Epoch 352/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0600 - accuracy: 0.8518\n",
      "Epoch 353/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0650 - accuracy: 0.8450\n",
      "Epoch 354/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0598 - accuracy: 0.8512\n",
      "Epoch 355/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0588 - accuracy: 0.8576 0s - loss: 0.0538 - accuracy: \n",
      "Epoch 356/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0661 - accuracy: 0.8419\n",
      "Epoch 357/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0638 - accuracy: 0.8436\n",
      "Epoch 358/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0728 - accuracy: 0.8290\n",
      "Epoch 359/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0708 - accuracy: 0.8324\n",
      "Epoch 360/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0606 - accuracy: 0.8506\n",
      "Epoch 361/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0576 - accuracy: 0.8588\n",
      "Epoch 362/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0576 - accuracy: 0.8571\n",
      "Epoch 363/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0624 - accuracy: 0.8505\n",
      "Epoch 364/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0637 - accuracy: 0.8476\n",
      "Epoch 365/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0619 - accuracy: 0.8502\n",
      "Epoch 366/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0669 - accuracy: 0.8474\n",
      "Epoch 367/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0656 - accuracy: 0.8406\n",
      "Epoch 368/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0629 - accuracy: 0.8456\n",
      "Epoch 369/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0630 - accuracy: 0.8462\n",
      "Epoch 370/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0610 - accuracy: 0.8503\n",
      "Epoch 371/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0792 - accuracy: 0.8209\n",
      "Epoch 372/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0737 - accuracy: 0.8278\n",
      "Epoch 373/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0618 - accuracy: 0.8515\n",
      "Epoch 374/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0590 - accuracy: 0.8523\n",
      "Epoch 375/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0563 - accuracy: 0.8618\n",
      "Epoch 376/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0602 - accuracy: 0.8556\n",
      "Epoch 377/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0650 - accuracy: 0.8448\n",
      "Epoch 378/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0784 - accuracy: 0.8189\n",
      "Epoch 379/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0731 - accuracy: 0.8284\n",
      "Epoch 380/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0614 - accuracy: 0.8493\n",
      "Epoch 381/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0598 - accuracy: 0.8548\n",
      "Epoch 382/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0579 - accuracy: 0.8567\n",
      "Epoch 383/500\n",
      "10665/10665 [==============================] - 0s 26us/step - loss: 0.0554 - accuracy: 0.8625\n",
      "Epoch 384/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0585 - accuracy: 0.8584\n",
      "Epoch 385/500\n",
      "10665/10665 [==============================] - 0s 26us/step - loss: 0.0672 - accuracy: 0.8435\n",
      "Epoch 386/500\n",
      "10665/10665 [==============================] - 0s 29us/step - loss: 0.0662 - accuracy: 0.8447\n",
      "Epoch 387/500\n",
      "10665/10665 [==============================] - 0s 27us/step - loss: 0.0609 - accuracy: 0.8519\n",
      "Epoch 388/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0588 - accuracy: 0.8559\n",
      "Epoch 389/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0558 - accuracy: 0.8599\n",
      "Epoch 390/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0620 - accuracy: 0.8551\n",
      "Epoch 391/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0789 - accuracy: 0.8233\n",
      "Epoch 392/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0662 - accuracy: 0.8431\n",
      "Epoch 393/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0595 - accuracy: 0.8548\n",
      "Epoch 394/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0560 - accuracy: 0.8631\n",
      "Epoch 395/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0544 - accuracy: 0.8651\n",
      "Epoch 396/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0545 - accuracy: 0.8631\n",
      "Epoch 397/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0547 - accuracy: 0.8650\n",
      "Epoch 398/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0621 - accuracy: 0.8504\n",
      "Epoch 399/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0551 - accuracy: 0.8643\n",
      "Epoch 400/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0583 - accuracy: 0.8590\n",
      "Epoch 401/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0560 - accuracy: 0.8614\n",
      "Epoch 402/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0697 - accuracy: 0.8473\n",
      "Epoch 403/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0779 - accuracy: 0.8261\n",
      "Epoch 404/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0625 - accuracy: 0.8452\n",
      "Epoch 405/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0663 - accuracy: 0.8463\n",
      "Epoch 406/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0677 - accuracy: 0.8384\n",
      "Epoch 407/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0596 - accuracy: 0.8545\n",
      "Epoch 408/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0556 - accuracy: 0.8627\n",
      "Epoch 409/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0603 - accuracy: 0.8580\n",
      "Epoch 410/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0545 - accuracy: 0.8642\n",
      "Epoch 411/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0537 - accuracy: 0.8635\n",
      "Epoch 412/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0572 - accuracy: 0.8588\n",
      "Epoch 413/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0716 - accuracy: 0.8460\n",
      "Epoch 414/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0756 - accuracy: 0.8189\n",
      "Epoch 415/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0626 - accuracy: 0.8476\n",
      "Epoch 416/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0608 - accuracy: 0.8532\n",
      "Epoch 417/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0577 - accuracy: 0.8607\n",
      "Epoch 418/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0568 - accuracy: 0.8604\n",
      "Epoch 419/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0704 - accuracy: 0.8444\n",
      "Epoch 420/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0610 - accuracy: 0.8522\n",
      "Epoch 421/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0578 - accuracy: 0.8601\n",
      "Epoch 422/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0567 - accuracy: 0.8604\n",
      "Epoch 423/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0515 - accuracy: 0.8728\n",
      "Epoch 424/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0529 - accuracy: 0.8712\n",
      "Epoch 425/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0548 - accuracy: 0.8668\n",
      "Epoch 426/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0701 - accuracy: 0.8458\n",
      "Epoch 427/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0687 - accuracy: 0.8404\n",
      "Epoch 428/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0745 - accuracy: 0.8323\n",
      "Epoch 429/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0622 - accuracy: 0.8491\n",
      "Epoch 430/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0623 - accuracy: 0.8527\n",
      "Epoch 431/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0585 - accuracy: 0.8574\n",
      "Epoch 432/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0539 - accuracy: 0.8665\n",
      "Epoch 433/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0551 - accuracy: 0.8661\n",
      "Epoch 434/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0621 - accuracy: 0.8561\n",
      "Epoch 435/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0699 - accuracy: 0.8392\n",
      "Epoch 436/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0568 - accuracy: 0.8624\n",
      "Epoch 437/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0557 - accuracy: 0.8633\n",
      "Epoch 438/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0545 - accuracy: 0.8629\n",
      "Epoch 439/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0606 - accuracy: 0.8570\n",
      "Epoch 440/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0524 - accuracy: 0.8693\n",
      "Epoch 441/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0524 - accuracy: 0.8710\n",
      "Epoch 442/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0665 - accuracy: 0.8472\n",
      "Epoch 443/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0564 - accuracy: 0.8640\n",
      "Epoch 444/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0563 - accuracy: 0.8655\n",
      "Epoch 445/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0560 - accuracy: 0.8654\n",
      "Epoch 446/500\n",
      "10665/10665 [==============================] - 0s 27us/step - loss: 0.0564 - accuracy: 0.8632\n",
      "Epoch 447/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0604 - accuracy: 0.8622\n",
      "Epoch 448/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0625 - accuracy: 0.8552\n",
      "Epoch 449/500\n",
      "10665/10665 [==============================] - 0s 31us/step - loss: 0.0610 - accuracy: 0.8586\n",
      "Epoch 450/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0577 - accuracy: 0.8594\n",
      "Epoch 451/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0628 - accuracy: 0.8569\n",
      "Epoch 452/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0564 - accuracy: 0.8654\n",
      "Epoch 453/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0593 - accuracy: 0.8630\n",
      "Epoch 454/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0637 - accuracy: 0.8498\n",
      "Epoch 455/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0548 - accuracy: 0.8666\n",
      "Epoch 456/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0619 - accuracy: 0.8570\n",
      "Epoch 457/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0609 - accuracy: 0.8546\n",
      "Epoch 458/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0532 - accuracy: 0.8685\n",
      "Epoch 459/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0520 - accuracy: 0.8713\n",
      "Epoch 460/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0540 - accuracy: 0.8708\n",
      "Epoch 461/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0579 - accuracy: 0.8620\n",
      "Epoch 462/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0645 - accuracy: 0.8489\n",
      "Epoch 463/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0556 - accuracy: 0.8638\n",
      "Epoch 464/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0521 - accuracy: 0.8690\n",
      "Epoch 465/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0497 - accuracy: 0.8776\n",
      "Epoch 466/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0533 - accuracy: 0.8682\n",
      "Epoch 467/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0519 - accuracy: 0.8767\n",
      "Epoch 468/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0588 - accuracy: 0.8637\n",
      "Epoch 469/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0612 - accuracy: 0.8576\n",
      "Epoch 470/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0715 - accuracy: 0.8397\n",
      "Epoch 471/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0674 - accuracy: 0.8423\n",
      "Epoch 472/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0589 - accuracy: 0.8575\n",
      "Epoch 473/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0513 - accuracy: 0.8706\n",
      "Epoch 474/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0508 - accuracy: 0.8744\n",
      "Epoch 475/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0492 - accuracy: 0.8789\n",
      "Epoch 476/500\n",
      "10665/10665 [==============================] - 0s 25us/step - loss: 0.0523 - accuracy: 0.8743\n",
      "Epoch 477/500\n",
      "10665/10665 [==============================] - 0s 27us/step - loss: 0.0601 - accuracy: 0.8609\n",
      "Epoch 478/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0584 - accuracy: 0.8659\n",
      "Epoch 479/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0615 - accuracy: 0.8590\n",
      "Epoch 480/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0584 - accuracy: 0.8627\n",
      "Epoch 481/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0632 - accuracy: 0.8531\n",
      "Epoch 482/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0561 - accuracy: 0.8638\n",
      "Epoch 483/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0511 - accuracy: 0.8740\n",
      "Epoch 484/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0512 - accuracy: 0.8729\n",
      "Epoch 485/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0594 - accuracy: 0.8623\n",
      "Epoch 486/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0570 - accuracy: 0.8658\n",
      "Epoch 487/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0572 - accuracy: 0.8657\n",
      "Epoch 488/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0502 - accuracy: 0.8823\n",
      "Epoch 489/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0493 - accuracy: 0.8775\n",
      "Epoch 490/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0502 - accuracy: 0.8803\n",
      "Epoch 491/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0701 - accuracy: 0.8472\n",
      "Epoch 492/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0708 - accuracy: 0.8418\n",
      "Epoch 493/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0614 - accuracy: 0.8544\n",
      "Epoch 494/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0626 - accuracy: 0.8519\n",
      "Epoch 495/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0535 - accuracy: 0.8709\n",
      "Epoch 496/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0538 - accuracy: 0.8706\n",
      "Epoch 497/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0557 - accuracy: 0.8673\n",
      "Epoch 498/500\n",
      "10665/10665 [==============================] - 0s 23us/step - loss: 0.0515 - accuracy: 0.8766\n",
      "Epoch 499/500\n",
      "10665/10665 [==============================] - 0s 22us/step - loss: 0.0610 - accuracy: 0.8633\n",
      "Epoch 500/500\n",
      "10665/10665 [==============================] - 0s 24us/step - loss: 0.0536 - accuracy: 0.8678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2601a88cd48>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.005\n",
    "\n",
    "def build_dqn(lr,n_output,input_dims):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(50, activation='relu', input_dim=input_dims))\n",
    "    model.add(Dense(80, activation='relu', input_dim=input_dims))\n",
    "    model.add(Dense(50, activation='relu', input_dim=input_dims))\n",
    "    model.add(Dense(30, activation='relu', input_dim=input_dims))\n",
    "    model.add(Dense(n_output, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(lr=alpha),\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "dqn = build_dqn(alpha,2,26)\n",
    "dqn.fit(x_train, to_categorical(y_train), epochs=500, batch_size=100,class_weight = {0: 0.85, 1: 0.15})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1898, 1461],\n",
       "       [  32, 7274]], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_NN = np.argmax((dqn.predict(x_train)), axis = 1)\n",
    "confusion_matrix(pred_NN,y_train)\n",
    "confusion_matrix(pred_NN,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 577, 1154],\n",
       "       [ 335, 3267]], dtype=int64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_NN = np.argmax((dqn.predict(x_test)), axis = 1)\n",
    "confusion_matrix(pred_NN,y_test)\n",
    "confusion_matrix(pred_NN,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.745147705078125% \n",
      " Error on training data: 0.254852294921875\n",
      "Accuracy on test data: 0.658916175365448% \n",
      " Error on test data: 0.341083824634552\n"
     ]
    }
   ],
   "source": [
    "model = dqn\n",
    "pred_train= model.predict(x_train)\n",
    "scores = model.evaluate(x_train, to_categorical(y_train), verbose=0)\n",
    "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
    " \n",
    "pred_test= model.predict(x_test)\n",
    "scores2 = model.evaluate(x_test, to_categorical(y_test), verbose=0)\n",
    "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model2.pickle', 'wb') as f:\n",
    "    pickle.dump(dqn, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
